{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4940c782",
   "metadata": {},
   "source": [
    "# ü§ñ Template Base para Agents LangChain\n",
    "\n",
    "**Objetivo:** Este notebook serve como um template completo e reutiliz√°vel para criar, testar e executar Agents com LangChain. Ele inclui as se√ß√µes essenciais, desde a configura√ß√£o at√© a execu√ß√£o, com exemplos pr√°ticos.\n",
    "\n",
    "**Estrutura:**\n",
    "1.  **Setup e Imports**: Bibliotecas essenciais.\n",
    "2.  **Credenciais e Configura√ß√µes**: API keys e configura√ß√µes globais.\n",
    "3.  **Modelos LLM**: Modelos de AI para diferentes tarefas.\n",
    "4.  **Tools (Ferramentas)**: Um conjunto de ferramentas √∫teis e prontas para uso.\n",
    "5.  **Prompts e Templates**: Estruturas de prompts para o agent.\n",
    "6.  **Sistema RAG (Opcional)**: L√≥gica para busca em documentos.\n",
    "7.  **Cria√ß√£o do Agent**: Montagem do agent com os componentes.\n",
    "8.  **Execu√ß√£o e Processamento**: Fun√ß√£o para invocar o agent.\n",
    "9.  **Fun√ß√£o Principal (Main)**: Orquestra√ß√£o e testes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d1f18c",
   "metadata": {},
   "source": [
    "## 1. Setup e Imports\n",
    "\n",
    "Nesta se√ß√£o, importamos todas as bibliotecas necess√°rias para o funcionamento do nosso sistema. √â uma boa pr√°tica manter todos os imports no in√≠cio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15284194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS B√ÅSICOS ===\n",
    "import os\n",
    "import asyncio\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "# === IMPORTS LANGCHAIN CORE ===\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain_community.cache import InMemoryCache\n",
    "\n",
    "# === IMPORTS PARA AGENTS ===\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "from langchain.tools import tool\n",
    "\n",
    "# === IMPORTS PARA RAG ===\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0868e26",
   "metadata": {},
   "source": [
    "## 2. Credenciais e Configura√ß√µes\n",
    "\n",
    "Aqui, configuramos as chaves de API e outras configura√ß√µes globais. O m√©todo ideal √© usar um arquivo `config.yaml` para manter as chaves seguras e fora do c√≥digo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34af8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_credenciais_e_config():\n",
    "    \"\"\"Carrega credenciais e define configura√ß√µes globais.\"\"\"\n",
    "    try:\n",
    "        # Carregar do config.yaml (m√©todo recomendado)\n",
    "        with open(\"../config/config.yaml\", \"r\") as config_file:\n",
    "            config = yaml.safe_load(config_file)\n",
    "        os.environ[\"OPENAI_API_KEY\"] = config[\"OPENAI_API_KEY\"]\n",
    "        print(\"üîë Credenciais carregadas do config.yaml\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ö†Ô∏è  Arquivo config.yaml n√£o encontrado. Usando credenciais de ambiente (se existirem).\")\n",
    "        # Se o arquivo n√£o existir, ele tentar√° usar vari√°veis de ambiente j√° configuradas\n",
    "        pass\n",
    "\n",
    "    # Configurar cache para otimiza√ß√£o de custos e velocidade\n",
    "    set_llm_cache(InMemoryCache())\n",
    "    print(\"‚ö° Cache em mem√≥ria ativado.\")\n",
    "\n",
    "# Executar a configura√ß√£o\n",
    "setup_credenciais_e_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6bbb28",
   "metadata": {},
   "source": [
    "## 3. Modelos LLM\n",
    "\n",
    "Definimos diferentes modelos de LLM para tarefas espec√≠ficas. Isso permite otimizar o custo e a performance, usando modelos mais baratos para tarefas simples e modelos mais poderosos para an√°lises complexas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360f61c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_modelos():\n",
    "    \"\"\"Configura e retorna um dicion√°rio de modelos LLM.\"\"\"\n",
    "    modelos = {\n",
    "        \"rapido\": ChatOpenAI(model='gpt-3.5-turbo', temperature=0.1, max_tokens=500),\n",
    "        \"premium\": ChatOpenAI(model='gpt-4o', temperature=0.3, max_tokens=1500),\n",
    "        \"tecnico\": ChatOpenAI(model='gpt-4', temperature=0, max_tokens=1000)\n",
    "    }\n",
    "    print(f\"ü§ñ Modelos configurados: {list(modelos.keys())}\")\n",
    "    return modelos\n",
    "\n",
    "# Inicializar modelos\n",
    "modelos_llm = setup_modelos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f75c78",
   "metadata": {},
   "source": [
    "## 4. Tools (Ferramentas)\n",
    "\n",
    "Esta √© a se√ß√£o mais importante para a funcionalidade do Agent. Aqui, definimos as ferramentas que o Agent pode usar para interagir com o mundo exterior, buscar informa√ß√µes ou executar a√ß√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8c650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DEFINI√á√ÉO DE TOOLS ===\n",
    "\n",
    "@tool\n",
    "def buscar_informacao_web(termo: str) -> str:\n",
    "    \"\"\"Busca informa√ß√µes gerais na web sobre um termo espec√≠fico. Use para perguntas abertas.\"\"\"\n",
    "    # Simula√ß√£o de uma busca na web (pode ser integrado com DuckDuckGo, Google Search API, etc.)\n",
    "    print(f\"üîé Buscando na web por: {termo}\")\n",
    "    return f\"Dados simulados da web sobre '{termo}'. A web √© vasta e cheia de informa√ß√µes.\" \n",
    "\n",
    "@tool\n",
    "def calcular_expressao(expressao: str) -> str:\n",
    "    \"\"\"Calcula express√µes matem√°ticas. Use para qualquer c√°lculo num√©rico.\"\"\"\n",
    "    try:\n",
    "        # CUIDADO: eval() √© inseguro em produ√ß√£o. Use uma biblioteca como 'numexpr' para seguran√ßa.\n",
    "        resultado = eval(expressao, {\"__builtins__\": {}}, {})\n",
    "        print(f\"üßÆ Calculando: {expressao} = {resultado}\")\n",
    "        return f\"O resultado de '{expressao}' √© {resultado}.\"\n",
    "    except Exception as e:\n",
    "        return f\"Erro ao calcular '{expressao}': {e}\"\n",
    "\n",
    "@tool\n",
    "def obter_data_e_hora_atual() -> str:\n",
    "    \"\"\"Retorna a data e a hora atuais. Use quando a pergunta envolver tempo.\"\"\"\n",
    "    now = datetime.now()\n",
    "    data_hora = now.strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
    "    print(f\"üïí Data e hora atual: {data_hora}\")\n",
    "    return f\"A data e hora atuais s√£o: {data_hora}.\"\n",
    "\n",
    "@tool\n",
    "def salvar_nota(conteudo: str) -> str:\n",
    "    \"\"\"Salva uma nota ou lembrete em um arquivo de texto. Use para persistir informa√ß√µes.\"\"\"\n",
    "    try:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        nome_arquivo = f\"nota_{timestamp}.txt\"\n",
    "        with open(nome_arquivo, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(conteudo)\n",
    "        print(f\"üíæ Nota salva em: {nome_arquivo}\")\n",
    "        return f\"Nota salva com sucesso no arquivo '{nome_arquivo}'.\"\n",
    "    except Exception as e:\n",
    "        return f\"Erro ao salvar nota: {e}\"\n",
    "\n",
    "# === COLE√á√ÉO DE TOOLS ===\n",
    "def criar_tools():\n",
    "    \"\"\"Retorna a lista de todas as tools dispon√≠veis para o agent.\"\"\"\n",
    "    return [buscar_informacao_web, calcular_expressao, obter_data_e_hora_atual, salvar_nota]\n",
    "\n",
    "lista_de_tools = criar_tools()\n",
    "print(f\"üõ†Ô∏è {len(lista_de_tools)} ferramentas prontas para uso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6306a41e",
   "metadata": {},
   "source": [
    "## 5. Prompts e Templates\n",
    "\n",
    "Definimos os templates de prompt que guiar√£o o comportamento do nosso Agent. O prompt do sistema √© crucial para definir a \"personalidade\" e as instru√ß√µes do Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49582c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_prompts():\n",
    "    \"\"\"Cria e retorna os templates de prompt para o agent.\"\"\"\n",
    "    prompts = {\n",
    "        \"agent_system\": ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"\n",
    "            Voc√™ √© um assistente de IA avan√ßado e proativo.\n",
    "            Seu objetivo √© ajudar o usu√°rio da forma mais completa poss√≠vel.\n",
    "            Voc√™ tem acesso a um conjunto de ferramentas para executar a√ß√µes.\n",
    "            \n",
    "            Instru√ß√µes:\n",
    "            1. Analise a pergunta do usu√°rio cuidadosamente.\n",
    "            2. Se a pergunta pode ser respondida diretamente, responda.\n",
    "            3. Se precisar de informa√ß√µes externas ou a√ß√µes, escolha a ferramenta mais apropriada.\n",
    "            4. Pense passo a passo sobre como usar as ferramentas para chegar √† resposta final.\n",
    "            5. Se uma ferramenta falhar, tente outra ou informe o usu√°rio sobre a limita√ß√£o.\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"placeholder\", \"{agent_scratchpad}\") # Onde o agent armazena seus pensamentos\n",
    "        ])\n",
    "    }\n",
    "    print(\"üìú Prompts do agent criados.\")\n",
    "    return prompts\n",
    "\n",
    "prompts_agent = criar_prompts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab6298b",
   "metadata": {},
   "source": [
    "## 6. Sistema RAG (Opcional)\n",
    "\n",
    "Esta se√ß√£o implementa um sistema de Retrieval-Augmented Generation (RAG). Ele permite que o Agent consulte uma base de conhecimento local (um arquivo de texto) para responder perguntas espec√≠ficas, em vez de usar apenas seu conhecimento geral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7e06f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_rag(caminho_arquivo: str):\n",
    "    \"\"\"Configura um sistema RAG a partir de um arquivo de texto.\"\"\"\n",
    "    try:\n",
    "        # Carregar documento\n",
    "        loader = TextLoader(caminho_arquivo, encoding=\"utf-8\")\n",
    "        documents = loader.load()\n",
    "        \n",
    "        # Dividir em chunks\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "        \n",
    "        # Criar embeddings e vector store\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        vectorstore = Chroma.from_documents(docs, embeddings)\n",
    "        \n",
    "        print(f\"üìö Sistema RAG configurado com {len(docs)} chunks.\")\n",
    "        return vectorstore\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Erro ao configurar RAG: {e}. O RAG ser√° desativado.\")\n",
    "        return None\n",
    "\n",
    "# Exemplo de configura√ß√£o do RAG (descomente para usar)\n",
    "# print(\"--- Configurando RAG ---\")\n",
    "# vectorstore_rag = setup_rag(\"../data/base_conhecimento_britadeira.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250df8c7",
   "metadata": {},
   "source": [
    "## 7. Cria√ß√£o do Agent\n",
    "\n",
    "Aqui, juntamos todos os componentes: o modelo LLM, as ferramentas e o prompt para criar o Agent Executor, que √© o c√©rebro que orquestra tudo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_agent(modelo_llm, tools, prompt_system):\n",
    "    \"\"\"Cria e compila o Agent Executor.\"\"\"\n",
    "    agent = create_openai_functions_agent(\n",
    "        llm=modelo_llm,\n",
    "        tools=tools,\n",
    "        prompt=prompt_system\n",
    "    )\n",
    "    \n",
    "    agent_executor = AgentExecutor(\n",
    "        agent=agent,\n",
    "        tools=tools,\n",
    "        verbose=True,  # Mostra os \"pensamentos\" do agent\n",
    "        return_intermediate_steps=False # Mude para True para debug detalhado\n",
    "    )\n",
    "    print(\"‚úÖ Agent Executor criado com sucesso!\")\n",
    "    return agent_executor\n",
    "\n",
    "# Criar o agent com os componentes definidos\n",
    "agent_executor = criar_agent(modelos_llm[\"premium\"], lista_de_tools, prompts_agent[\"agent_system\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d7f6f0",
   "metadata": {},
   "source": [
    "## 8. Execu√ß√£o e Processamento\n",
    "\n",
    "Esta fun√ß√£o encapsula a l√≥gica de como uma pergunta do usu√°rio √© processada. Ela pode incluir a busca RAG antes de passar a pergunta para o Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def processar_pergunta(pergunta: str, executor, vectorstore=None):\n",
    "    \"\"\"Processa uma pergunta, opcionalmente usando RAG, e invoca o agent.\"\"\"\n",
    "    print(f\"\\n--- üöÄ Processando Pergunta ---\")\n",
    "    print(f\"üó£Ô∏è Usu√°rio: {pergunta}\")\n",
    "    \n",
    "    input_para_agent = {\"input\": pergunta}\n",
    "    \n",
    "    # Se o RAG estiver configurado, busca contexto e o adiciona ao input\n",
    "    if vectorstore:\n",
    "        docs_relevantes = vectorstore.similarity_search(pergunta, k=2)\n",
    "        contexto_rag = \"\\n\\n\".join([doc.page_content for doc in docs_relevantes])\n",
    "        input_para_agent[\"input\"] += f\"\\n\\n--- CONTEXTO ADICIONAL ---\\n{contexto_rag}\"\n",
    "        print(\"üìö Contexto RAG adicionado.\")\n",
    "        \n",
    "    # Invocar o agent\n",
    "    resultado = await executor.ainvoke(input_para_agent)\n",
    "    \n",
    "    return resultado[\"output\"]\n",
    "\n",
    "print(\"‚öôÔ∏è Fun√ß√£o de processamento pronta.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef06e3b",
   "metadata": {},
   "source": [
    "## 9. Fun√ß√£o Principal (Main)\n",
    "\n",
    "Este √© o ponto de entrada para testar o sistema. Defina sua pergunta aqui e execute a c√©lula para ver o Agent em a√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4b875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    \"\"\"Fun√ß√£o principal para orquestrar e testar o agent.\"\"\"\n",
    "    \n",
    "    # === PERGUNTA DE TESTE ===\n",
    "    # Altere a pergunta abaixo para testar diferentes funcionalidades\n",
    "    pergunta_teste = \"Qual a data e hora de hoje? Depois, calcule (150 * 3) / 5 e salve o resultado em uma nota.\"\n",
    "    \n",
    "    # Para testar o RAG, primeiro configure o vectorstore na c√©lula 6\n",
    "    # e depois use uma pergunta relacionada ao documento.\n",
    "    # pergunta_teste = \"Como consertar uma britadeira que n√£o liga?\"\n",
    "    \n",
    "    # Processar a pergunta\n",
    "    resposta_final = await processar_pergunta(\n",
    "        pergunta=pergunta_teste, \n",
    "        executor=agent_executor, \n",
    "        vectorstore=None # Mude para vectorstore_rag para usar RAG\n",
    "    )\n",
    "    \n",
    "    print(\"\\n--- ‚úÖ Resposta Final ---\")\n",
    "    print(resposta_final)\n",
    "\n",
    "# === EXECUTAR O NOTEBOOK ===\n",
    "# Usamos 'await' aqui porque o Jupyter/IPython j√° tem um loop de eventos rodando.\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
