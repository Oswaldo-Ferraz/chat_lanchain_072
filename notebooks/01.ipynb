{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a38f6d",
   "metadata": {},
   "source": [
    "# Chatbot com Rag - 001\n",
    "\n",
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50c078b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Setup concluído com sucesso!\n",
      "🔥 Cache ativado para respostas mais rápidas!\n",
      "⚡ Modelo rápido: gpt-3.5-turbo\n",
      "🔧 Modelo premium: gpt-4\n",
      "🌡️ Temperatura: 0.0\n",
      "🚀 Sistema otimizado pronto para uso!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "import yaml\n",
    "import os\n",
    "import asyncio\n",
    "import time\n",
    "import asyncio  \n",
    "\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "os.environ[\"OPENAI_API_KEY\"] = config[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Configurar cache para respostas mais rápidas\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "# Modelo rápido para análise inicial\n",
    "openai_rapido = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)\n",
    "# Modelo premium para resposta final\n",
    "openai_premium = ChatOpenAI(model='gpt-4', temperature=0)\n",
    "\n",
    "# Confirmação de que o setup foi realizado com sucesso\n",
    "print(\"✅ Setup concluído com sucesso!\")\n",
    "print(\"🔥 Cache ativado para respostas mais rápidas!\")\n",
    "print(f\"⚡ Modelo rápido: {openai_rapido.model_name}\")\n",
    "print(f\"🔧 Modelo premium: {openai_premium.model_name}\")\n",
    "print(f\"🌡️ Temperatura: {openai_premium.temperature}\")\n",
    "print(\"🚀 Sistema otimizado pronto para uso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92806b50",
   "metadata": {},
   "source": [
    "# Carregar os Documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c2af491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos carregados:\n",
      "- Base de Conhecimento Aprimorada para a Britadeira XP500\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader('base_conhecimento_britadeira.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "print(\"Documentos carregados:\")\n",
    "for doc in documents:\n",
    "    first_line = doc.page_content.split('\\n')[0]\n",
    "    print(f\"- {first_line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1246bcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cadeias otimizadas definidas com sucesso!\n",
      "⚡ Análises iniciais: GPT-3.5 Turbo (rápido)\n",
      "🎯 Resposta final: GPT-4 (premium)\n"
     ]
    }
   ],
   "source": [
    "# Cadeias otimizadas com modelos híbridos\n",
    "chain_base_conhecimento = prompt_base_conhecimento | openai_rapido      # GPT-3.5 para análise rápida\n",
    "chain_historico_conversas = prompt_historico_conversas | openai_rapido  # GPT-3.5 para análise rápida  \n",
    "chain_final = prompt_final | openai_premium                             # GPT-4 para resposta final\n",
    "\n",
    "print(\"✅ Cadeias otimizadas definidas com sucesso!\")\n",
    "print(\"⚡ Análises iniciais: GPT-3.5 Turbo (rápido)\")\n",
    "print(\"🎯 Resposta final: GPT-4 (premium)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb732859",
   "metadata": {},
   "source": [
    "# Passando dados e executando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d41bcaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏱️ Iniciando execução das chains otimizadas...\n",
      "⚡ Análises paralelas (GPT-3.5) executadas em: 1.18s\n",
      "⚡ Análises paralelas (GPT-3.5) executadas em: 1.18s\n",
      "🎯 Resposta final (GPT-4) executada em: 3.29s\n",
      "🏁 TEMPO TOTAL OTIMIZADO: 4.48s\n",
      "\n",
      "============================================================\n",
      "📊 RESULTADOS DAS ANÁLISES:\n",
      "============================================================\n",
      "🔍 Resultado Base de Conhecimento:\n",
      " Aguarde 30 segundos após conectar a bateria para que o sistema inicialize e verifique se o interruptor liga/desliga está na posição correta. Se o problema persistir, contate o suporte técnico pelo 0800 555 5555.\n",
      "\n",
      "----------------------------------------\n",
      "📝 Resultado Histórico de Conversas:\n",
      " Chatbot: Nesse caso, pode ser um problema com o interruptor de ligar/desligar da britadeira. Você já tentou verificar se ele está funcionando corretamente?\n",
      "\n",
      "----------------------------------------\n",
      "🎯 Resultado Final Combinado:\n",
      " Após conectar a bateria, aguarde 30 segundos para que o sistema inicialize. Durante esse tempo, verifique se o interruptor liga/desliga está na posição correta. Isso pode ser um problema com o interruptor de ligar/desligar da britadeira. Se o problema persistir, contate o suporte técnico pelo 0800 555 5555.\n",
      "🎯 Resposta final (GPT-4) executada em: 3.29s\n",
      "🏁 TEMPO TOTAL OTIMIZADO: 4.48s\n",
      "\n",
      "============================================================\n",
      "📊 RESULTADOS DAS ANÁLISES:\n",
      "============================================================\n",
      "🔍 Resultado Base de Conhecimento:\n",
      " Aguarde 30 segundos após conectar a bateria para que o sistema inicialize e verifique se o interruptor liga/desliga está na posição correta. Se o problema persistir, contate o suporte técnico pelo 0800 555 5555.\n",
      "\n",
      "----------------------------------------\n",
      "📝 Resultado Histórico de Conversas:\n",
      " Chatbot: Nesse caso, pode ser um problema com o interruptor de ligar/desligar da britadeira. Você já tentou verificar se ele está funcionando corretamente?\n",
      "\n",
      "----------------------------------------\n",
      "🎯 Resultado Final Combinado:\n",
      " Após conectar a bateria, aguarde 30 segundos para que o sistema inicialize. Durante esse tempo, verifique se o interruptor liga/desliga está na posição correta. Isso pode ser um problema com o interruptor de ligar/desligar da britadeira. Se o problema persistir, contate o suporte técnico pelo 0800 555 5555.\n"
     ]
    }
   ],
   "source": [
    "async def executar_chains():\n",
    "    # Executar as duas primeiras chains em paralelo\n",
    "    resultado_base, resultado_historico = await asyncio.gather(\n",
    "        chain_base_conhecimento.ainvoke({\"context\": inputs[\"context\"], \"question\": inputs[\"question\"]}),\n",
    "        chain_historico_conversas.ainvoke({\"historico\": inputs[\"historico\"], \"question\": inputs[\"question\"]})\n",
    "    )\n",
    "    \n",
    "    # Executar chain final com os resultados\n",
    "    resultado_final = await chain_final.ainvoke({\n",
    "        \"resposta_base_conhecimento\": resultado_base, \n",
    "        \"resposta_historico_conversas\": resultado_historico\n",
    "    })\n",
    "    \n",
    "    return resultado_base, resultado_historico, resultado_final\n",
    "\n",
    "# Executar e atribuir às mesmas variáveis\n",
    "# Execução Assíncrona Otimizada com Medição de Tempo\n",
    "async def executar_chains_otimizada():\n",
    "    inicio = time.time()\n",
    "    print(\"⏱️ Iniciando execução das chains otimizadas...\")\n",
    "    \n",
    "    # Executar as duas primeiras chains em paralelo (GPT-3.5)\n",
    "    inicio_paralelo = time.time()\n",
    "    resultado_base, resultado_historico = await asyncio.gather(\n",
    "        chain_base_conhecimento.ainvoke({\"context\": inputs[\"context\"], \"question\": inputs[\"question\"]}),\n",
    "        chain_historico_conversas.ainvoke({\"historico\": inputs[\"historico\"], \"question\": inputs[\"question\"]})\n",
    "    )\n",
    "    fim_paralelo = time.time()\n",
    "    print(f\"⚡ Análises paralelas (GPT-3.5) executadas em: {fim_paralelo - inicio_paralelo:.2f}s\")\n",
    "    \n",
    "    # Executar chain final com GPT-4\n",
    "    inicio_final = time.time()\n",
    "    resultado_final = await chain_final.ainvoke({\n",
    "        \"resposta_base_conhecimento\": resultado_base, \n",
    "        \"resposta_historico_conversas\": resultado_historico\n",
    "    })\n",
    "    fim_final = time.time()\n",
    "    print(f\"🎯 Resposta final (GPT-4) executada em: {fim_final - inicio_final:.2f}s\")\n",
    "    \n",
    "    fim = time.time()\n",
    "    print(f\"🏁 TEMPO TOTAL OTIMIZADO: {fim - inicio:.2f}s\")\n",
    "    \n",
    "    return resultado_base, resultado_historico, resultado_final\n",
    "\n",
    "# Executar versão otimizada\n",
    "resultado_base_conhecimento, resultado_historico_conversas, resultado_final = await executar_chains_otimizada()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 RESULTADOS DAS ANÁLISES:\")\n",
    "print(\"=\"*60)\n",
    "print(\"🔍 Resultado Base de Conhecimento:\\n\", resultado_base_conhecimento.content)\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"📝 Resultado Histórico de Conversas:\\n\", resultado_historico_conversas.content)\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"🎯 Resultado Final Combinado:\\n\", resultado_final.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ea4adc",
   "metadata": {},
   "source": [
    "# 🎯 Resposta Final para o Cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9c9f15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 CHATBOT RAG OTIMIZADO - RESPOSTA EM TEMPO REAL\n",
      "==================================================\n",
      "❓ Pergunta:\n",
      "Minha britadeira não liga. Eu já verifiquei e a bateria está carregada e conectada corretamente\n",
      "\n",
      "==================================================\n",
      "💬 Resposta:\n",
      "ApósApós conectar a conectar a bateria bateria, ag, aguardeuarde 30 segundos para 30 segundos para que o que o sistema inicial sistema inicialize.ize. Durante Durante esse tempo esse tempo, ver, verifique se o interruptifique se o interruptor lor liga/diga/desligaesliga está na está na posição cor posição correta,reta, como menc como mencionadoionado anteriormente, pode anteriormente, pode ser um ser um problema com problema com o interrupt o interruptor deor de ligar ligar/des/desligarligar da brit da britadeira. Seadeira. Se o problema o problema persistir persistir, cont, contate oate o suporte suporte técnico técnico pelo  pelo 0800 5550800 555 555 5555.\n",
      "\n",
      "==================================================\n",
      "⚡ Streaming executado em: 3.26s\n",
      "✅ Resposta otimizada gerada com base na documentação\n",
      "técnica e histórico de conversas\n",
      "🔥 Sistema utilizando: Cache + Async + Modelos Híbridos + Streaming\n",
      "5.\n",
      "\n",
      "==================================================\n",
      "⚡ Streaming executado em: 3.26s\n",
      "✅ Resposta otimizada gerada com base na documentação\n",
      "técnica e histórico de conversas\n",
      "🔥 Sistema utilizando: Cache + Async + Modelos Híbridos + Streaming\n"
     ]
    }
   ],
   "source": [
    "# 🎯 Resposta Final com Streaming em Tempo Real\n",
    "async def resposta_streaming():\n",
    "    print(\"🤖 CHATBOT RAG OTIMIZADO - RESPOSTA EM TEMPO REAL\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"❓ Pergunta:\\n{pergunta}\")\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"💬 Resposta:\")\n",
    "    \n",
    "    # Streaming da resposta final em tempo real\n",
    "    resposta_completa = \"\"\n",
    "    inicio_stream = time.time()\n",
    "    \n",
    "    async for chunk in chain_final.astream({\n",
    "        \"resposta_base_conhecimento\": resultado_base_conhecimento,\n",
    "        \"resposta_historico_conversas\": resultado_historico_conversas\n",
    "    }):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "        resposta_completa += chunk.content\n",
    "    \n",
    "    fim_stream = time.time()\n",
    "    \n",
    "    print(f\"\\n\\n\" + \"=\" * 50)\n",
    "    print(f\"⚡ Streaming executado em: {fim_stream - inicio_stream:.2f}s\")\n",
    "    print(\"✅ Resposta otimizada gerada com base na documentação\\ntécnica e histórico de conversas\")\n",
    "    print(\"🔥 Sistema utilizando: Cache + Async + Modelos Híbridos + Streaming\")\n",
    "    \n",
    "    return resposta_completa\n",
    "\n",
    "# Executar resposta com streaming\n",
    "resposta_final_streaming = await resposta_streaming()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
