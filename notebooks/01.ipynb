{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a38f6d",
   "metadata": {},
   "source": [
    "# Chatbot com Rag - 001\n",
    "\n",
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50c078b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Setup concluÃ­do com sucesso!\n",
      "ğŸ”¥ Cache ativado para respostas mais rÃ¡pidas!\n",
      "âš¡ Modelo rÃ¡pido: gpt-3.5-turbo\n",
      "ğŸ”§ Modelo premium: gpt-4\n",
      "ğŸŒ¡ï¸ Temperatura: 0.0\n",
      "ğŸš€ Sistema otimizado pronto para uso!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "import yaml\n",
    "import os\n",
    "import asyncio\n",
    "import time\n",
    "import asyncio  \n",
    "\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "os.environ[\"OPENAI_API_KEY\"] = config[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Configurar cache para respostas mais rÃ¡pidas\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "# Modelo rÃ¡pido para anÃ¡lise inicial\n",
    "openai_rapido = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)\n",
    "# Modelo premium para resposta final\n",
    "openai_premium = ChatOpenAI(model='gpt-4', temperature=0)\n",
    "\n",
    "# ConfirmaÃ§Ã£o de que o setup foi realizado com sucesso\n",
    "print(\"âœ… Setup concluÃ­do com sucesso!\")\n",
    "print(\"ğŸ”¥ Cache ativado para respostas mais rÃ¡pidas!\")\n",
    "print(f\"âš¡ Modelo rÃ¡pido: {openai_rapido.model_name}\")\n",
    "print(f\"ğŸ”§ Modelo premium: {openai_premium.model_name}\")\n",
    "print(f\"ğŸŒ¡ï¸ Temperatura: {openai_premium.temperature}\")\n",
    "print(\"ğŸš€ Sistema otimizado pronto para uso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92806b50",
   "metadata": {},
   "source": [
    "# Carregar os Documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c2af491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos carregados:\n",
      "- Base de Conhecimento Aprimorada para a Britadeira XP500\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader('base_conhecimento_britadeira.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "print(\"Documentos carregados:\")\n",
    "for doc in documents:\n",
    "    first_line = doc.page_content.split('\\n')[0]\n",
    "    print(f\"- {first_line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1246bcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cadeias otimizadas definidas com sucesso!\n",
      "âš¡ AnÃ¡lises iniciais: GPT-3.5 Turbo (rÃ¡pido)\n",
      "ğŸ¯ Resposta final: GPT-4 (premium)\n"
     ]
    }
   ],
   "source": [
    "# Cadeias otimizadas com modelos hÃ­bridos\n",
    "chain_base_conhecimento = prompt_base_conhecimento | openai_rapido      # GPT-3.5 para anÃ¡lise rÃ¡pida\n",
    "chain_historico_conversas = prompt_historico_conversas | openai_rapido  # GPT-3.5 para anÃ¡lise rÃ¡pida  \n",
    "chain_final = prompt_final | openai_premium                             # GPT-4 para resposta final\n",
    "\n",
    "print(\"âœ… Cadeias otimizadas definidas com sucesso!\")\n",
    "print(\"âš¡ AnÃ¡lises iniciais: GPT-3.5 Turbo (rÃ¡pido)\")\n",
    "print(\"ğŸ¯ Resposta final: GPT-4 (premium)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb732859",
   "metadata": {},
   "source": [
    "# Passando dados e executando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d41bcaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â±ï¸ Iniciando execuÃ§Ã£o das chains otimizadas...\n",
      "âš¡ AnÃ¡lises paralelas (GPT-3.5) executadas em: 1.18s\n",
      "âš¡ AnÃ¡lises paralelas (GPT-3.5) executadas em: 1.18s\n",
      "ğŸ¯ Resposta final (GPT-4) executada em: 3.29s\n",
      "ğŸ TEMPO TOTAL OTIMIZADO: 4.48s\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š RESULTADOS DAS ANÃLISES:\n",
      "============================================================\n",
      "ğŸ” Resultado Base de Conhecimento:\n",
      " Aguarde 30 segundos apÃ³s conectar a bateria para que o sistema inicialize e verifique se o interruptor liga/desliga estÃ¡ na posiÃ§Ã£o correta. Se o problema persistir, contate o suporte tÃ©cnico pelo 0800 555 5555.\n",
      "\n",
      "----------------------------------------\n",
      "ğŸ“ Resultado HistÃ³rico de Conversas:\n",
      " Chatbot: Nesse caso, pode ser um problema com o interruptor de ligar/desligar da britadeira. VocÃª jÃ¡ tentou verificar se ele estÃ¡ funcionando corretamente?\n",
      "\n",
      "----------------------------------------\n",
      "ğŸ¯ Resultado Final Combinado:\n",
      " ApÃ³s conectar a bateria, aguarde 30 segundos para que o sistema inicialize. Durante esse tempo, verifique se o interruptor liga/desliga estÃ¡ na posiÃ§Ã£o correta. Isso pode ser um problema com o interruptor de ligar/desligar da britadeira. Se o problema persistir, contate o suporte tÃ©cnico pelo 0800 555 5555.\n",
      "ğŸ¯ Resposta final (GPT-4) executada em: 3.29s\n",
      "ğŸ TEMPO TOTAL OTIMIZADO: 4.48s\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š RESULTADOS DAS ANÃLISES:\n",
      "============================================================\n",
      "ğŸ” Resultado Base de Conhecimento:\n",
      " Aguarde 30 segundos apÃ³s conectar a bateria para que o sistema inicialize e verifique se o interruptor liga/desliga estÃ¡ na posiÃ§Ã£o correta. Se o problema persistir, contate o suporte tÃ©cnico pelo 0800 555 5555.\n",
      "\n",
      "----------------------------------------\n",
      "ğŸ“ Resultado HistÃ³rico de Conversas:\n",
      " Chatbot: Nesse caso, pode ser um problema com o interruptor de ligar/desligar da britadeira. VocÃª jÃ¡ tentou verificar se ele estÃ¡ funcionando corretamente?\n",
      "\n",
      "----------------------------------------\n",
      "ğŸ¯ Resultado Final Combinado:\n",
      " ApÃ³s conectar a bateria, aguarde 30 segundos para que o sistema inicialize. Durante esse tempo, verifique se o interruptor liga/desliga estÃ¡ na posiÃ§Ã£o correta. Isso pode ser um problema com o interruptor de ligar/desligar da britadeira. Se o problema persistir, contate o suporte tÃ©cnico pelo 0800 555 5555.\n"
     ]
    }
   ],
   "source": [
    "async def executar_chains():\n",
    "    # Executar as duas primeiras chains em paralelo\n",
    "    resultado_base, resultado_historico = await asyncio.gather(\n",
    "        chain_base_conhecimento.ainvoke({\"context\": inputs[\"context\"], \"question\": inputs[\"question\"]}),\n",
    "        chain_historico_conversas.ainvoke({\"historico\": inputs[\"historico\"], \"question\": inputs[\"question\"]})\n",
    "    )\n",
    "    \n",
    "    # Executar chain final com os resultados\n",
    "    resultado_final = await chain_final.ainvoke({\n",
    "        \"resposta_base_conhecimento\": resultado_base, \n",
    "        \"resposta_historico_conversas\": resultado_historico\n",
    "    })\n",
    "    \n",
    "    return resultado_base, resultado_historico, resultado_final\n",
    "\n",
    "# Executar e atribuir Ã s mesmas variÃ¡veis\n",
    "# ExecuÃ§Ã£o AssÃ­ncrona Otimizada com MediÃ§Ã£o de Tempo\n",
    "async def executar_chains_otimizada():\n",
    "    inicio = time.time()\n",
    "    print(\"â±ï¸ Iniciando execuÃ§Ã£o das chains otimizadas...\")\n",
    "    \n",
    "    # Executar as duas primeiras chains em paralelo (GPT-3.5)\n",
    "    inicio_paralelo = time.time()\n",
    "    resultado_base, resultado_historico = await asyncio.gather(\n",
    "        chain_base_conhecimento.ainvoke({\"context\": inputs[\"context\"], \"question\": inputs[\"question\"]}),\n",
    "        chain_historico_conversas.ainvoke({\"historico\": inputs[\"historico\"], \"question\": inputs[\"question\"]})\n",
    "    )\n",
    "    fim_paralelo = time.time()\n",
    "    print(f\"âš¡ AnÃ¡lises paralelas (GPT-3.5) executadas em: {fim_paralelo - inicio_paralelo:.2f}s\")\n",
    "    \n",
    "    # Executar chain final com GPT-4\n",
    "    inicio_final = time.time()\n",
    "    resultado_final = await chain_final.ainvoke({\n",
    "        \"resposta_base_conhecimento\": resultado_base, \n",
    "        \"resposta_historico_conversas\": resultado_historico\n",
    "    })\n",
    "    fim_final = time.time()\n",
    "    print(f\"ğŸ¯ Resposta final (GPT-4) executada em: {fim_final - inicio_final:.2f}s\")\n",
    "    \n",
    "    fim = time.time()\n",
    "    print(f\"ğŸ TEMPO TOTAL OTIMIZADO: {fim - inicio:.2f}s\")\n",
    "    \n",
    "    return resultado_base, resultado_historico, resultado_final\n",
    "\n",
    "# Executar versÃ£o otimizada\n",
    "resultado_base_conhecimento, resultado_historico_conversas, resultado_final = await executar_chains_otimizada()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š RESULTADOS DAS ANÃLISES:\")\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ” Resultado Base de Conhecimento:\\n\", resultado_base_conhecimento.content)\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"ğŸ“ Resultado HistÃ³rico de Conversas:\\n\", resultado_historico_conversas.content)\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"ğŸ¯ Resultado Final Combinado:\\n\", resultado_final.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ea4adc",
   "metadata": {},
   "source": [
    "# ğŸ¯ Resposta Final para o Cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9c9f15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– CHATBOT RAG OTIMIZADO - RESPOSTA EM TEMPO REAL\n",
      "==================================================\n",
      "â“ Pergunta:\n",
      "Minha britadeira nÃ£o liga. Eu jÃ¡ verifiquei e a bateria estÃ¡ carregada e conectada corretamente\n",
      "\n",
      "==================================================\n",
      "ğŸ’¬ Resposta:\n",
      "ApÃ³sApÃ³s conectar a conectar a bateria bateria, ag, aguardeuarde 30 segundos para 30 segundos para que o que o sistema inicial sistema inicialize.ize. Durante Durante esse tempo esse tempo, ver, verifique se o interruptifique se o interruptor lor liga/diga/desligaesliga estÃ¡ na estÃ¡ na posiÃ§Ã£o cor posiÃ§Ã£o correta,reta, como menc como mencionadoionado anteriormente, pode anteriormente, pode ser um ser um problema com problema com o interrupt o interruptor deor de ligar ligar/des/desligarligar da brit da britadeira. Seadeira. Se o problema o problema persistir persistir, cont, contate oate o suporte suporte tÃ©cnico tÃ©cnico pelo  pelo 0800 5550800 555 555 5555.\n",
      "\n",
      "==================================================\n",
      "âš¡ Streaming executado em: 3.26s\n",
      "âœ… Resposta otimizada gerada com base na documentaÃ§Ã£o\n",
      "tÃ©cnica e histÃ³rico de conversas\n",
      "ğŸ”¥ Sistema utilizando: Cache + Async + Modelos HÃ­bridos + Streaming\n",
      "5.\n",
      "\n",
      "==================================================\n",
      "âš¡ Streaming executado em: 3.26s\n",
      "âœ… Resposta otimizada gerada com base na documentaÃ§Ã£o\n",
      "tÃ©cnica e histÃ³rico de conversas\n",
      "ğŸ”¥ Sistema utilizando: Cache + Async + Modelos HÃ­bridos + Streaming\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¯ Resposta Final com Streaming em Tempo Real\n",
    "async def resposta_streaming():\n",
    "    print(\"ğŸ¤– CHATBOT RAG OTIMIZADO - RESPOSTA EM TEMPO REAL\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"â“ Pergunta:\\n{pergunta}\")\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"ğŸ’¬ Resposta:\")\n",
    "    \n",
    "    # Streaming da resposta final em tempo real\n",
    "    resposta_completa = \"\"\n",
    "    inicio_stream = time.time()\n",
    "    \n",
    "    async for chunk in chain_final.astream({\n",
    "        \"resposta_base_conhecimento\": resultado_base_conhecimento,\n",
    "        \"resposta_historico_conversas\": resultado_historico_conversas\n",
    "    }):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "        resposta_completa += chunk.content\n",
    "    \n",
    "    fim_stream = time.time()\n",
    "    \n",
    "    print(f\"\\n\\n\" + \"=\" * 50)\n",
    "    print(f\"âš¡ Streaming executado em: {fim_stream - inicio_stream:.2f}s\")\n",
    "    print(\"âœ… Resposta otimizada gerada com base na documentaÃ§Ã£o\\ntÃ©cnica e histÃ³rico de conversas\")\n",
    "    print(\"ğŸ”¥ Sistema utilizando: Cache + Async + Modelos HÃ­bridos + Streaming\")\n",
    "    \n",
    "    return resposta_completa\n",
    "\n",
    "# Executar resposta com streaming\n",
    "resposta_final_streaming = await resposta_streaming()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
